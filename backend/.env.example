# API Server configuration
API_HOST=0.0.0.0
API_PORT=8000

# CORS configuration - comma-separated list of allowed origins
CORS_ORIGINS=http://localhost:3000,https://yourapp.com

# OpenAI configuration
OPENAI_API_KEY=your_openai_api_key

# =============================================================================
# MODEL CONFIGURATION
# Configure different models for different purposes to optimize cost vs capability
# =============================================================================

# Main conversation model - used for chat responses, integration, and response rendering
# Recommendation: Use a capable model (gpt-4o, gpt-4-turbo) for best user experience
# Cost impact: High (most frequent usage)
DEFAULT_MODEL=gpt-4o-mini

# Router model - lightweight model for routing decisions (chat vs search vs analyzer)
# Recommendation: Use a fast, cheap model (gpt-4o-mini, gpt-3.5-turbo) since routing is simple classification
# Cost impact: Low (quick decisions only)
ROUTER_MODEL=gpt-4o-mini

# Research model - used for autonomous background research workflow
# Recommendation: Use a capable analytical model (gpt-4o, gpt-4-turbo) for thorough research
# Cost impact: Medium (background tasks, less frequent than chat)
RESEARCH_MODEL=gpt-4o-mini

# Topic extraction model - extracts research-worthy topics from conversations
# Recommendation: Use a structured output capable model (gpt-4o-mini works well)
# Cost impact: Low (structured output tasks)
TOPIC_EXTRACTION_MODEL=gpt-4o-mini

# =============================================================================
# EXTERNAL API CONFIGURATION
# =============================================================================

# Perplexity configuration for web search
PERPLEXITY_API_KEY=your_perplexity_api_key
# Perplexity model for web search - use 'sonar' for their default search model
PERPLEXITY_MODEL=sonar

# PubMed E-utilities configuration (no API key required, but email recommended)
# Email helps NCBI contact you if there are issues with your requests
PUBMED_EMAIL=your_email@example.com

# Zep Memory Configuration (optional)
ZEP_API_KEY=your_zep_api_key_here
ZEP_ENABLED=false

# Langchain configs
LANGCHAIN_TRACING_V2=True
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your_langchain_api_key
LANGCHAIN_PROJECT=researcher-prototype

# =============================================================================
# SYSTEM CONFIGURATION
# =============================================================================

# Logging configuration
# Available levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Message management configuration
MAX_MESSAGES_IN_STATE=4

# Topic extraction configuration
TOPIC_MIN_CONFIDENCE=0.8
TOPIC_MAX_SUGGESTIONS=3
TOPIC_EXTRACTION_TEMPERATURE=0.3
TOPIC_EXTRACTION_MAX_TOKENS=800

# Autonomous Research Engine configuration
RESEARCH_ENGINE_ENABLED=true
RESEARCH_QUALITY_THRESHOLD=0.6
RESEARCH_MAX_TOPICS_PER_USER=3
RESEARCH_FINDINGS_RETENTION_DAYS=30

# Maximum active research topics per user (prevent overwhelming users with too many topics)
MAX_ACTIVE_RESEARCH_TOPICS_PER_USER=10

# Motivation system configuration
MOTIVATION_CHECK_INTERVAL=60
MOTIVATION_THRESHOLD=5.0
MOTIVATION_BOREDOM_RATE=0.0002
MOTIVATION_CURIOSITY_DECAY=0.0001
MOTIVATION_TIREDNESS_DECAY=0.0001
MOTIVATION_SATISFACTION_DECAY=0.0001

# Per-topic motivation configuration
TOPIC_MOTIVATION_THRESHOLD=0.5
TOPIC_ENGAGEMENT_WEIGHT=0.3
TOPIC_QUALITY_WEIGHT=0.2
TOPIC_STALENESS_SCALE=0.0001

# =============================================================================
# TOPIC EXPANSION CONFIGURATION
# Configure the LLM-powered topic expansion system
# =============================================================================

# Topic expansion LLM confidence threshold (0.0-1.0)
# Higher values = more selective, lower values = more topics generated
EXPANSION_LLM_CONFIDENCE_THRESHOLD=0.6

# Maximum depth for expansion chains (cost control)
EXPANSION_MAX_DEPTH=2

# LLM model and timeout for expansion calls
EXPANSION_LLM_MODEL=gpt-4o-mini
EXPANSION_LLM_TIMEOUT_SECONDS=30

# Maximum parallel expansion research tasks
EXPANSION_MAX_PARALLEL=2

# Topic expansion breadth control (prevent topic explosion)
EXPANSION_MAX_TOTAL_TOPICS_PER_USER=10      # Maximum total expansion topics per user
EXPANSION_MAX_UNREVIEWED_TOPICS=5           # Maximum unreviewed topics before pausing expansion  
EXPANSION_REVIEW_ENGAGEMENT_THRESHOLD=0.2   # Engagement threshold that counts as "reviewed"

# Admin Interface Configuration (CHANGE THESE IN PRODUCTION!)
ADMIN_PASSWORD=admin123
ADMIN_JWT_SECRET=your-secret-key-change-in-production
ADMIN_JWT_EXPIRE_MINUTES=480
